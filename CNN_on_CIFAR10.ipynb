{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-12-27T20:00:20.003135Z","iopub.status.busy":"2024-12-27T20:00:20.002912Z","iopub.status.idle":"2024-12-27T20:00:25.295580Z","shell.execute_reply":"2024-12-27T20:00:25.294805Z","shell.execute_reply.started":"2024-12-27T20:00:20.003113Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.24 (you have 1.4.15). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n","  check_for_updates()\n"]}],"source":["from __future__ import print_function\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","import numpy as np\n","import os\n","from tqdm import tqdm\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","import multiprocessing"]},{"cell_type":"markdown","metadata":{},"source":["**Target:**\n","\n","1. Works on CIFAR10 Dataset\n","2. Has the architecture to C1C2C3C40 (No MaxPooling, but convolutions, where the last one has a stride of 2 instead) (NO restriction on using 1x1)\n","3. Total RF must be more than 44\n","4. One of the layers must use Depthwise Separable Convolution\n","5. One of the layers must use Dilated Convolution\n","use GAP (compulsory):- add FC after GAP to target #of classes (optional)\n","6. uses albumentation library and apply:\n","    a. horizontal flip\n","    b. shiftScaleRotate\n","    c. coarseDropout (max_holes = 1, max_height=16px,   max_width=16, min_holes = 1, min_height=16px, min_width=16px, fill_value=(mean of your dataset), mask_fill_value = None)\n","7. achieve 85% accuracy, as many epochs as you want. \n","8. Total Params to be less than 200k."]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-12-27T20:00:28.834505Z","iopub.status.busy":"2024-12-27T20:00:28.834213Z","iopub.status.idle":"2024-12-27T20:00:28.839469Z","shell.execute_reply":"2024-12-27T20:00:28.838736Z","shell.execute_reply.started":"2024-12-27T20:00:28.834482Z"},"trusted":true},"outputs":[],"source":["class CIFAR10Dataset(datasets.CIFAR10):\n","    def __init__(self, root, train=True, transform=None):\n","        super(CIFAR10Dataset, self).__init__(\n","            root=root, train=train, download=True, transform=None\n","        )\n","        self.albumentations_transform = transform\n","\n","    def __getitem__(self, index):\n","        image, label = super(CIFAR10Dataset, self).__getitem__(index)\n","        image = np.array(image)  # Convert PIL Image to numpy array\n","\n","        if self.albumentations_transform:\n","            transformed = self.albumentations_transform(image=image)\n","            image = transformed[\"image\"]\n","\n","        return image, label"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-12-27T20:00:31.381318Z","iopub.status.busy":"2024-12-27T20:00:31.381001Z","iopub.status.idle":"2024-12-27T20:00:31.386918Z","shell.execute_reply":"2024-12-27T20:00:31.385994Z","shell.execute_reply.started":"2024-12-27T20:00:31.381292Z"},"trusted":true},"outputs":[],"source":["def load_cifar10_with_albumentations(device, use_cuda, config_dict, albumentations_transform):\n","    torch.manual_seed(config_dict[\"seed\"])\n","    if device == \"cuda\":\n","        torch.cuda.manual_seed(config_dict[\"seed\"])\n","    batch_size = config_dict[\"batch_size\"]\n","    kwargs = (\n","        {\"num_workers\": multiprocessing.cpu_count(), \"pin_memory\": True}\n","        if use_cuda\n","        else {}\n","    )\n","\n","    train_dataset = CIFAR10Dataset(root=\"./data\", train=True, transform=albumentations_transform)\n","    test_dataset = CIFAR10Dataset(root=\"./data\", train=False, transform=albumentations_transform)\n","\n","    train_dataset, test_dataset\n","\n","    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, **kwargs)\n","    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, **kwargs)\n","\n","    return train_loader, test_loader   "]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-12-27T20:00:34.920308Z","iopub.status.busy":"2024-12-27T20:00:34.920034Z","iopub.status.idle":"2024-12-27T20:00:40.043020Z","shell.execute_reply":"2024-12-27T20:00:40.041700Z","shell.execute_reply.started":"2024-12-27T20:00:34.920287Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-4-4b1afc660952>:26: UserWarning: Argument 'fill' is not valid and will be ignored.\n","  A.CoarseDropout(p=0.1, fill=(0.49139968, 0.48215827, 0.44653124)),\n"]},{"name":"stdout","output_type":"stream","text":["cuda\n","Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 170498071/170498071 [00:01<00:00, 96134763.45it/s] \n"]},{"name":"stdout","output_type":"stream","text":["Extracting ./data/cifar-10-python.tar.gz to ./data\n","Files already downloaded and verified\n"]}],"source":["# For reproducibility\n","\n","SEED = 1\n","\n","use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","print(device)\n","\n","# train & test dataloader\n","\n","config_dict = {\"seed\": SEED, \"batch_size\": 64}\n","albumentations_transform = A.Compose(\n","        [\n","            A.HorizontalFlip(p=0.5),\n","            A.ShiftScaleRotate(p=0.05),\n","            A.CoarseDropout(p=0.1, fill=(0.49139968, 0.48215827, 0.44653124)),\n","            A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n","            ToTensorV2(),\n","        ]\n","    )\n","\n","train_loader, test_loader = load_cifar10_with_albumentations(\n","        device=device,\n","        use_cuda=use_cuda,\n","        config_dict=config_dict,\n","        albumentations_transform=albumentations_transform#,\n","    )"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-12-27T20:00:43.282199Z","iopub.status.busy":"2024-12-27T20:00:43.281917Z","iopub.status.idle":"2024-12-27T20:00:43.289566Z","shell.execute_reply":"2024-12-27T20:00:43.288639Z","shell.execute_reply.started":"2024-12-27T20:00:43.282178Z"},"trusted":true},"outputs":[],"source":["train_losses = []\n","test_losses = []\n","train_acc = []\n","test_acc = []\n","\n","def train(model, device, train_loader, optimizer, epoch):\n","  model.train()\n","  \n","  correct = 0\n","  processed = 0\n","  pbar = tqdm(train_loader)\n","  for batch_idx, (data, target) in enumerate(pbar):\n","    # get samples\n","    data, target = data.to(device), target.to(device)\n","\n","    # Init\n","    optimizer.zero_grad()\n","    # In PyTorch, we need to set the gradients to zero before starting to do backpropragation because PyTorch accumulates the gradients on subsequent backward passes. \n","    # Because of this, when you start your training loop, ideally you should zero out the gradients so that you do the parameter update correctly.\n","\n","    # Predict\n","    y_pred = model(data)\n","\n","    # Calculate loss\n","    loss = F.nll_loss(y_pred, target)\n","    train_losses.append(loss)\n","\n","    # Backpropagation\n","    loss.backward()\n","    optimizer.step()\n","\n","    # Update pbar-tqdm\n","    \n","    pred = y_pred.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n","    correct += pred.eq(target.view_as(pred)).sum().item()\n","    processed += len(data)\n","\n","    pbar.set_description(desc= f'Loss={loss.item()} Batch_id={batch_idx} Accuracy={100*correct/processed:0.2f}')\n","    train_acc.append(100*correct/processed)\n","\n","def test(model, device, test_loader):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n","            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","    test_loss /= len(test_loader.dataset)\n","    test_losses.append(test_loss)\n","\n","    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n","        test_loss, correct, len(test_loader.dataset),\n","        100. * correct / len(test_loader.dataset)))\n","    \n","    test_acc.append(100. * correct / len(test_loader.dataset))"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-12-27T20:00:52.129482Z","iopub.status.busy":"2024-12-27T20:00:52.129175Z","iopub.status.idle":"2024-12-27T20:00:52.136823Z","shell.execute_reply":"2024-12-27T20:00:52.135865Z","shell.execute_reply.started":"2024-12-27T20:00:52.129457Z"},"trusted":true},"outputs":[],"source":["class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        \n","        # C1 Block - Regular Convolution\n","        self.conv1 = nn.Sequential(\n","            nn.Conv2d(3, 32, kernel_size=3, padding=1, bias=False),\n","            nn.BatchNorm2d(32),\n","            nn.ReLU(),\n","            nn.Conv2d(32, 48, kernel_size=5, padding=2, bias=False),  # Increased kernel size\n","            nn.BatchNorm2d(48),\n","            nn.ReLU(),\n","        )\n","        \n","        # C2 Block - Depthwise Separable Convolution\n","        self.conv2 = nn.Sequential(\n","            nn.Conv2d(48, 48, kernel_size=3, padding=1, groups=24, bias=False),\n","            nn.Conv2d(48, 64, kernel_size=1, bias=False),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),\n","            nn.Conv2d(64, 64, kernel_size=3, padding=1, bias=False),  # Added layer\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),\n","        )\n","        \n","        # C3 Block - Dilated Convolution\n","        self.conv3 = nn.Sequential(\n","            nn.Conv2d(64, 64, kernel_size=3, padding=4, dilation=4, bias=False),  # Increased dilation\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(),\n","        )\n","        \n","        # C4 Block - Strided Convolution\n","        self.conv4 = nn.Sequential(\n","            nn.Conv2d(64, 96, kernel_size=3, stride=2, padding=1, bias=False),\n","            nn.BatchNorm2d(96),\n","            nn.ReLU(),\n","        )\n","        \n","        self.gap = nn.AdaptiveAvgPool2d(1)\n","        self.fc = nn.Linear(96, 10)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.conv2(x)\n","        x = self.conv3(x)\n","        x = self.conv4(x)\n","        x = self.gap(x)\n","        x = x.view(-1, 96)\n","        x = self.fc(x)\n","        return F.log_softmax(x, dim=1)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-12-27T20:00:57.447012Z","iopub.status.busy":"2024-12-27T20:00:57.446680Z","iopub.status.idle":"2024-12-27T20:01:02.669881Z","shell.execute_reply":"2024-12-27T20:01:02.668883Z","shell.execute_reply.started":"2024-12-27T20:00:57.446984Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 32, 32, 32]             864\n","       BatchNorm2d-2           [-1, 32, 32, 32]              64\n","              ReLU-3           [-1, 32, 32, 32]               0\n","            Conv2d-4           [-1, 48, 32, 32]          38,400\n","       BatchNorm2d-5           [-1, 48, 32, 32]              96\n","              ReLU-6           [-1, 48, 32, 32]               0\n","            Conv2d-7           [-1, 48, 32, 32]             864\n","            Conv2d-8           [-1, 64, 32, 32]           3,072\n","       BatchNorm2d-9           [-1, 64, 32, 32]             128\n","             ReLU-10           [-1, 64, 32, 32]               0\n","           Conv2d-11           [-1, 64, 32, 32]          36,864\n","      BatchNorm2d-12           [-1, 64, 32, 32]             128\n","             ReLU-13           [-1, 64, 32, 32]               0\n","           Conv2d-14           [-1, 64, 32, 32]          36,864\n","      BatchNorm2d-15           [-1, 64, 32, 32]             128\n","             ReLU-16           [-1, 64, 32, 32]               0\n","           Conv2d-17           [-1, 96, 16, 16]          55,296\n","      BatchNorm2d-18           [-1, 96, 16, 16]             192\n","             ReLU-19           [-1, 96, 16, 16]               0\n","AdaptiveAvgPool2d-20             [-1, 96, 1, 1]               0\n","           Linear-21                   [-1, 10]             970\n","================================================================\n","Total params: 173,930\n","Trainable params: 173,930\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.01\n","Forward/backward pass size (MB): 7.31\n","Params size (MB): 0.66\n","Estimated Total Size (MB): 7.99\n","----------------------------------------------------------------\n"]}],"source":["!pip install torchsummary\n","from torchsummary import summary\n","model = Net().to(device)\n","summary(model, input_size=(3, 32, 32))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-12-27T20:01:15.532561Z","iopub.status.busy":"2024-12-27T20:01:15.532217Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["EPOCH: 0\n"]},{"name":"stderr","output_type":"stream","text":["Loss=1.284513235092163 Batch_id=781 Accuracy=44.60: 100%|██████████| 782/782 [00:32<00:00, 23.75it/s] \n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 1.4615, Accuracy: 4684/10000 (46.84%)\n","\n","EPOCH: 1\n"]},{"name":"stderr","output_type":"stream","text":["Loss=1.0822097063064575 Batch_id=781 Accuracy=59.50: 100%|██████████| 782/782 [00:32<00:00, 24.19it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 1.1063, Accuracy: 6046/10000 (60.46%)\n","\n","EPOCH: 2\n"]},{"name":"stderr","output_type":"stream","text":["Loss=0.7968603372573853 Batch_id=781 Accuracy=66.30: 100%|██████████| 782/782 [00:32<00:00, 24.25it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.9710, Accuracy: 6619/10000 (66.19%)\n","\n","EPOCH: 3\n"]},{"name":"stderr","output_type":"stream","text":["Loss=0.6355998516082764 Batch_id=781 Accuracy=71.27: 100%|██████████| 782/782 [00:30<00:00, 25.24it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.8058, Accuracy: 7130/10000 (71.30%)\n","\n","EPOCH: 4\n"]},{"name":"stderr","output_type":"stream","text":["Loss=0.20071467757225037 Batch_id=781 Accuracy=74.64: 100%|██████████| 782/782 [00:31<00:00, 24.48it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.8880, Accuracy: 6897/10000 (68.97%)\n","\n","EPOCH: 5\n"]},{"name":"stderr","output_type":"stream","text":["Loss=0.5494881272315979 Batch_id=781 Accuracy=76.77: 100%|██████████| 782/782 [00:30<00:00, 25.94it/s] \n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.6941, Accuracy: 7552/10000 (75.52%)\n","\n","EPOCH: 6\n"]},{"name":"stderr","output_type":"stream","text":["Loss=0.8475427627563477 Batch_id=781 Accuracy=78.67: 100%|██████████| 782/782 [00:31<00:00, 24.61it/s] \n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.6794, Accuracy: 7661/10000 (76.61%)\n","\n","EPOCH: 7\n"]},{"name":"stderr","output_type":"stream","text":["Loss=0.3551082909107208 Batch_id=781 Accuracy=80.31: 100%|██████████| 782/782 [00:30<00:00, 25.68it/s] \n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.6345, Accuracy: 7818/10000 (78.18%)\n","\n","EPOCH: 8\n"]},{"name":"stderr","output_type":"stream","text":["Loss=0.3669706881046295 Batch_id=781 Accuracy=81.26: 100%|██████████| 782/782 [00:31<00:00, 24.77it/s] \n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.6320, Accuracy: 7805/10000 (78.05%)\n","\n","EPOCH: 9\n"]},{"name":"stderr","output_type":"stream","text":["Loss=0.8171730041503906 Batch_id=781 Accuracy=82.36: 100%|██████████| 782/782 [00:31<00:00, 25.01it/s] \n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.6290, Accuracy: 7823/10000 (78.23%)\n","\n","EPOCH: 10\n"]},{"name":"stderr","output_type":"stream","text":["Loss=0.8088398575782776 Batch_id=781 Accuracy=83.26: 100%|██████████| 782/782 [00:31<00:00, 25.07it/s] \n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.6948, Accuracy: 7628/10000 (76.28%)\n","\n","EPOCH: 11\n"]},{"name":"stderr","output_type":"stream","text":["Loss=0.1935376524925232 Batch_id=781 Accuracy=84.09: 100%|██████████| 782/782 [00:30<00:00, 25.37it/s] \n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.6405, Accuracy: 7837/10000 (78.37%)\n","\n","EPOCH: 12\n"]},{"name":"stderr","output_type":"stream","text":["Loss=0.3873443603515625 Batch_id=781 Accuracy=84.56: 100%|██████████| 782/782 [00:32<00:00, 24.34it/s] \n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.5226, Accuracy: 8191/10000 (81.91%)\n","\n","EPOCH: 13\n"]},{"name":"stderr","output_type":"stream","text":["Loss=0.3189619183540344 Batch_id=781 Accuracy=85.63: 100%|██████████| 782/782 [00:32<00:00, 24.35it/s] \n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.5432, Accuracy: 8132/10000 (81.32%)\n","\n","EPOCH: 14\n"]},{"name":"stderr","output_type":"stream","text":["Loss=0.3648768961429596 Batch_id=781 Accuracy=86.18: 100%|██████████| 782/782 [00:31<00:00, 24.81it/s] \n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.5477, Accuracy: 8153/10000 (81.53%)\n","\n","EPOCH: 15\n"]},{"name":"stderr","output_type":"stream","text":["Loss=0.4654165506362915 Batch_id=781 Accuracy=86.80: 100%|██████████| 782/782 [00:32<00:00, 24.23it/s] \n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.4959, Accuracy: 8293/10000 (82.93%)\n","\n","EPOCH: 16\n"]},{"name":"stderr","output_type":"stream","text":["Loss=0.3261142373085022 Batch_id=781 Accuracy=87.27: 100%|██████████| 782/782 [00:30<00:00, 25.64it/s] \n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.5052, Accuracy: 8293/10000 (82.93%)\n","\n","EPOCH: 17\n"]},{"name":"stderr","output_type":"stream","text":["Loss=0.3853275179862976 Batch_id=781 Accuracy=88.03: 100%|██████████| 782/782 [00:32<00:00, 24.07it/s] \n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.5013, Accuracy: 8287/10000 (82.87%)\n","\n","EPOCH: 18\n"]},{"name":"stderr","output_type":"stream","text":["Loss=0.883782148361206 Batch_id=781 Accuracy=88.78: 100%|██████████| 782/782 [00:32<00:00, 24.24it/s]  \n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.4781, Accuracy: 8385/10000 (83.85%)\n","\n","EPOCH: 19\n"]},{"name":"stderr","output_type":"stream","text":["Loss=0.39649349451065063 Batch_id=781 Accuracy=89.29: 100%|██████████| 782/782 [00:30<00:00, 25.85it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.4884, Accuracy: 8307/10000 (83.07%)\n","\n","EPOCH: 20\n"]},{"name":"stderr","output_type":"stream","text":["Loss=0.46497803926467896 Batch_id=781 Accuracy=89.70: 100%|██████████| 782/782 [00:31<00:00, 25.08it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.4371, Accuracy: 8495/10000 (84.95%)\n","\n","EPOCH: 21\n"]},{"name":"stderr","output_type":"stream","text":["Loss=0.29612860083580017 Batch_id=781 Accuracy=90.18: 100%|██████████| 782/782 [00:31<00:00, 24.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.4492, Accuracy: 8434/10000 (84.34%)\n","\n","EPOCH: 22\n"]},{"name":"stderr","output_type":"stream","text":["Loss=0.7159926295280457 Batch_id=781 Accuracy=90.84: 100%|██████████| 782/782 [00:31<00:00, 24.59it/s] \n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.4494, Accuracy: 8487/10000 (84.87%)\n","\n","EPOCH: 23\n"]},{"name":"stderr","output_type":"stream","text":["Loss=0.23242917656898499 Batch_id=781 Accuracy=91.10: 100%|██████████| 782/782 [00:32<00:00, 24.19it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.4281, Accuracy: 8521/10000 (85.21%)\n","\n","EPOCH: 24\n"]},{"name":"stderr","output_type":"stream","text":["Loss=0.1462191492319107 Batch_id=781 Accuracy=91.61: 100%|██████████| 782/782 [00:31<00:00, 25.14it/s] \n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.4240, Accuracy: 8563/10000 (85.63%)\n","\n","EPOCH: 25\n"]},{"name":"stderr","output_type":"stream","text":["Loss=0.4644079804420471 Batch_id=781 Accuracy=92.16: 100%|██████████| 782/782 [00:30<00:00, 25.42it/s] \n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.4173, Accuracy: 8592/10000 (85.92%)\n","\n","EPOCH: 26\n"]},{"name":"stderr","output_type":"stream","text":["Loss=0.4637536108493805 Batch_id=781 Accuracy=92.28: 100%|██████████| 782/782 [00:31<00:00, 24.48it/s] \n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.4191, Accuracy: 8562/10000 (85.62%)\n","\n","EPOCH: 27\n"]},{"name":"stderr","output_type":"stream","text":["Loss=0.09505604952573776 Batch_id=781 Accuracy=92.80: 100%|██████████| 782/782 [00:32<00:00, 24.27it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.4176, Accuracy: 8594/10000 (85.94%)\n","\n","EPOCH: 28\n"]},{"name":"stderr","output_type":"stream","text":["Loss=0.2846538722515106 Batch_id=781 Accuracy=92.78: 100%|██████████| 782/782 [00:31<00:00, 24.86it/s]  \n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.4126, Accuracy: 8603/10000 (86.03%)\n","\n","EPOCH: 29\n"]},{"name":"stderr","output_type":"stream","text":["Loss=0.14075541496276855 Batch_id=781 Accuracy=92.95: 100%|██████████| 782/782 [00:31<00:00, 24.65it/s] \n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.4172, Accuracy: 8596/10000 (85.96%)\n","\n","EPOCH: 30\n"]},{"name":"stderr","output_type":"stream","text":["Loss=0.28987351059913635 Batch_id=781 Accuracy=92.90: 100%|██████████| 782/782 [00:31<00:00, 24.62it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.4250, Accuracy: 8595/10000 (85.95%)\n","\n","EPOCH: 31\n"]},{"name":"stderr","output_type":"stream","text":["Loss=0.6214544773101807 Batch_id=781 Accuracy=92.90: 100%|██████████| 782/782 [00:31<00:00, 25.07it/s] \n"]},{"name":"stdout","output_type":"stream","text":["\n","Test set: Average loss: 0.4237, Accuracy: 8573/10000 (85.73%)\n","\n","EPOCH: 32\n"]},{"name":"stderr","output_type":"stream","text":["Loss=0.21403680741786957 Batch_id=658 Accuracy=93.09:  84%|████████▍ | 658/782 [00:26<00:05, 23.73it/s]"]}],"source":["from torch.optim.lr_scheduler import StepLR\n","import math\n","\n","# model =  Net().to(device)\n","optimizer = optim.SGD(model.parameters(), lr=0.015, momentum=0.9,nesterov=True,\n","                         weight_decay=1e-4)\n","\n","def warmup_cosine_schedule(epoch):\n","        warmup_epochs = 3  # Reduced warmup period\n","        if epoch < warmup_epochs:\n","            return (epoch + 1) / warmup_epochs\n","        return 0.5 * (1 + math.cos(math.pi * (epoch - warmup_epochs) / (30 - warmup_epochs)))\n","    \n","# scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n","scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=warmup_cosine_schedule)\n","\n","\n","EPOCHS = 35\n","for epoch in range(EPOCHS):\n","    print(\"EPOCH:\", epoch)\n","    train(model, device, train_loader, optimizer, epoch)\n","    scheduler.step()\n","    test(model, device, test_loader)"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30822,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
